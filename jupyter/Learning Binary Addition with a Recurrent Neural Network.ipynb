{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Binary Addition with a Recurrent Neural Network (RNN)\n",
    "\n",
    "This example of an RNN is mostly directly taken from @iamtrask's [blog post](https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/). The code below takes his code and builds a class out of it so that you can parameterize your own RNN.\n",
    "\n",
    "Also, it adds a `train` method that can be used to perform a custom addition operation after the net has been trained.\n",
    "\n",
    "This RNN learns how to do binary addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, copy\n",
    "\n",
    "class RNN:\n",
    "    \n",
    "    def __init__(self, binary_dim=8, alpha=0.1, input_dim=2, hidden_dim=16, output_dim=1, iterations=10000):\n",
    "        self.binary_dim = binary_dim\n",
    "        self.alpha = alpha\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.iterations = iterations\n",
    "        self.largest_number = 0\n",
    "        self.int2binary = {}\n",
    "        \n",
    "        np.random.seed()\n",
    "        \n",
    "        self.prepare_int2binary_map()\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_derivative(self,x):\n",
    "        return x*(1-x)\n",
    "    \n",
    "    def prepare_int2binary_map(self):\n",
    "        self.largest_number = pow(2, self.binary_dim)\n",
    "        binary = np.unpackbits(np.array([range(self.largest_number)], dtype=np.uint8).T, axis=1)\n",
    "        for i in range(self.largest_number):\n",
    "            self.int2binary[i] = binary[i]\n",
    "    \n",
    "    def test(self, a_int, b_int):\n",
    "        \n",
    "        correct_answer = a_int + b_int\n",
    "        \n",
    "        a = self.int2binary[a_int]\n",
    "        b = self.int2binary[b_int]\n",
    "        \n",
    "        layer1_values = list()\n",
    "        layer1_values.append(np.zeros(self.hidden_dim))\n",
    "        layer2_values = np.zeros(self.binary_dim)\n",
    "        \n",
    "        for position in range(self.binary_dim):\n",
    "                \n",
    "            # generate input and output\n",
    "            X = np.array([[a[self.binary_dim - position - 1],b[self.binary_dim - position - 1]]])\n",
    "\n",
    "            # hidden layer\n",
    "            layer1 = self.sigmoid(np.dot(X,self.W0) + np.dot(layer1_values[-1],self.Wh))\n",
    "            layer1_values.append(layer1)\n",
    "\n",
    "            # output layer\n",
    "            layer2_values[self.binary_dim - position - 1] = self.sigmoid(np.dot(layer1,self.W1))\n",
    "        \n",
    "        guess = np.packbits(np.round(layer2_values).astype(int))\n",
    "        #print(\"%d + %d = %d\\tGuess: %d\" % (a_int, b_int, correct_answer, np.packbits(np.round(layer2_values).astype(int))))\n",
    "        return guess\n",
    "        \n",
    "    def train(self):\n",
    "        #initialize weights\n",
    "        self.W0 = 2*np.random.random((self.input_dim, self.hidden_dim)) - 1\n",
    "        self.W1 = 2*np.random.random((self.hidden_dim, self.output_dim)) - 1\n",
    "        self.Wh = 2*np.random.random((self.hidden_dim, self.hidden_dim)) - 1\n",
    "        \n",
    "        W0_update = np.zeros_like(self.W0)\n",
    "        W1_update = np.zeros_like(self.W1)\n",
    "        Wh_update = np.zeros_like(self.Wh)\n",
    "        \n",
    "        for j in range(self.iterations):\n",
    "            # create a random binary addition problem\n",
    "            a_int = np.random.randint(self.largest_number/2)\n",
    "            a = self.int2binary[a_int]\n",
    "            \n",
    "            b_int = np.random.randint(self.largest_number/2)\n",
    "            b = self.int2binary[b_int]\n",
    "            \n",
    "            # true answer\n",
    "            c_int = a_int + b_int\n",
    "            c = self.int2binary[c_int]\n",
    "            \n",
    "            #print(\"%d + %d = %d\" %(a_int, b_int, c_int))\n",
    "            \n",
    "            # place to store our best guess\n",
    "            d = np.zeros_like(c)\n",
    "            \n",
    "            overall_error = 0\n",
    "            \n",
    "            layer2_deltas = list()\n",
    "            layer1_values = list()\n",
    "            layer1_values.append(np.zeros(self.hidden_dim))\n",
    "    \n",
    "            for position in range(self.binary_dim):\n",
    "                \n",
    "                # generate input and output\n",
    "                X = np.array([[a[self.binary_dim - position - 1],b[self.binary_dim - position - 1]]])\n",
    "                y = np.array([[c[self.binary_dim - position - 1]]]).T\n",
    "                \n",
    "                # hidden layer\n",
    "                layer1 = self.sigmoid(np.dot(X,self.W0) + np.dot(layer1_values[-1],self.Wh))\n",
    "                \n",
    "                # output layer\n",
    "                layer2 = self.sigmoid(np.dot(layer1,self.W1))\n",
    "                \n",
    "                #print(layer2)\n",
    "                \n",
    "                # measure error\n",
    "                layer2_error = y - layer2\n",
    "                layer2_deltas.append((layer2_error)*self.sigmoid_output_derivative(layer2))\n",
    "                overall_error += np.abs(layer2_error[0])\n",
    "                \n",
    "                # decode guessed solution\n",
    "                d[self.binary_dim - position - 1] = np.round(layer2[0][0])\n",
    "                \n",
    "                # store hidden layer for use in next time step\n",
    "                layer1_values.append(copy.deepcopy(layer1))\n",
    "            \n",
    "            future_layer1_delta = np.zeros(self.hidden_dim)\n",
    "            \n",
    "            for position in range(self.binary_dim):\n",
    "                \n",
    "                X = np.array([[a[position],b[position]]])\n",
    "                layer1 = layer1_values[-position - 1]\n",
    "                prev_layer1 = layer1_values[-position - 2]\n",
    "                \n",
    "                # error at output layer\n",
    "                layer2_delta = layer2_deltas[-position-1]\n",
    "                \n",
    "                # error at hidden layer\n",
    "                layer1_delta = \\\n",
    "                    (future_layer1_delta.dot(self.Wh.T) + \\\n",
    "                    layer2_delta.dot(self.W1.T)) * \\\n",
    "                    self.sigmoid_output_derivative(layer1)\n",
    "                    \n",
    "                # update all weights\n",
    "                W1_update += np.atleast_2d(layer1).T.dot(layer2_delta)\n",
    "                Wh_update += np.atleast_2d(prev_layer1).T.dot(layer1_delta)\n",
    "                W0_update += X.T.dot(layer1_delta)\n",
    "                \n",
    "                future_layer1_delta = layer1_delta\n",
    "                \n",
    "            self.W0 += W0_update * self.alpha\n",
    "            self.W1 += W1_update * self.alpha\n",
    "            self.Wh += Wh_update * self.alpha\n",
    "            \n",
    "            W0_update *= 0\n",
    "            W1_update *= 0\n",
    "            Wh_update *= 0\n",
    "            \n",
    "            # print progress\n",
    "            if j % 2000 == 0:\n",
    "                print(\"Error: %.5f\" % overall_error)\n",
    "                #print(\"Pred: %s\" % str(d))\n",
    "                #print(\"True: %s\" % str(c))\n",
    "                out = 0\n",
    "                for index,x in enumerate(reversed(d)):\n",
    "                    out += x*pow(2, index)\n",
    "                print(\"%d + %d = %d\" % (a_int,b_int,out))\n",
    "                print(\"---------\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Next, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 3.81032\n",
      "57 + 1 = 254\n",
      "---------\n",
      "Error: 4.23229\n",
      "42 + 89 = 118\n",
      "---------\n",
      "Error: 3.58486\n",
      "53 + 46 = 91\n",
      "---------\n",
      "Error: 1.00315\n",
      "85 + 20 = 105\n",
      "---------\n",
      "Error: 0.63371\n",
      "60 + 45 = 105\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(iterations=10000)\n",
    "rnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Now, let's see how our model does if we give it a whole bunch of random addition problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 10000/10000\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "num_attempts = 10000\n",
    "answers = np.zeros((num_attempts,2))\n",
    "num_correct = 0\n",
    "\n",
    "for i in range(num_attempts):\n",
    "    a_int = np.random.randint(rnn.largest_number/2)\n",
    "    b_int = np.random.randint(rnn.largest_number/2)\n",
    "    answers[i][0] = rnn.test(a_int, b_int)\n",
    "    answers[i][1] = a_int + b_int\n",
    "    if answers[i][0] == answers[i][1]:\n",
    "        num_correct += 1\n",
    "    \n",
    "print(\"Correct: %d/%d\" % (num_correct, num_attempts))\n",
    "print(\"Accuracy: %.3f\" % (float(num_correct)/num_attempts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "100% accuracy on 10000 examples. Nice work, RNN!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
